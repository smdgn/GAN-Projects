{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "# Necessary imports\n",
    "import sys\n",
    "sys.path.append('src/')\n",
    "import utils, models, layers, metrics\n",
    "from tensorflow.keras.layers import BatchNormalization, Conv2D, \\\n",
    "    Dense, UpSampling2D, GlobalMaxPool2D, GlobalAveragePooling2D, Flatten, Embedding, Concatenate\n",
    "from utils import cast_img\n",
    "from layers import BConv2D, LConv2D, SelfAttention, ResBlock, ConditionalBatchNorm,ConditionalDenseBatchNorm, Projection, Convolution, DenselyConnected, TransposedConvolution\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model('Models/20210625-141706/generator')#http://10.28.202.5:8888/tree/tensorflow/Samed/Models/20210625-141706/generator\n",
    "#new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 20\n",
    "intraFID = metrics.IntraFID(input_shape=(299,299,3), num_samples=num_samples)\n",
    "intraFID._load_data()\n",
    "#for image_class in intraFID.image_chunks:\n",
    "    #for image in image_class:\n",
    "        #plt.figure()\n",
    "        #plt.imshow((image + 1.0)*0.5)\n",
    "        #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('Models/20210625-141706/generator')#http://10.28.202.5:8888/tree/tensorflow/Samed/Models/20210625-141706/generator\n",
    "#new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-16-8cc47496b2f8>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-8cc47496b2f8>\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    image = np.cast(image + 1.0) * 127.5, 'uint8'))\u001b[0m\n\u001b[0m                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def generate(model, z,y):\n",
    "    return model([z,y], training=False)\n",
    "\n",
    "y_list = [tf.fill([10, 1], i) for i in range(10)]\n",
    "z_fid = tf.random.normal((10, 10, 100))\n",
    "fake_images = [generate(new_model,z,y2) for y2, z in zip(y_list, z_fid)]\n",
    "i = 0\n",
    "for image_class in fake_images:\n",
    "    for image in image_class:\n",
    "        image = np.cast(image + 1.0) * 127.5, 'uint8'))\n",
    "        im = Image.fromarray(image)\n",
    "        im.save(\"image\"+str(i)+\".jpeg\")\n",
    "        #plt.figure()\n",
    "        #plt.imshow((image + 1.0)*0.5)\n",
    "        #plt.show()\n",
    "fid_classes, fid_scalar = intraFID.get_fid(fake_images)\n",
    "print(fid_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(hp):\n",
    "    input_image = tf.keras.Input(shape=(32, 32, 3))\n",
    "    input_label = tf.keras.Input(shape=(1,))\n",
    "    \n",
    "    xy = input_image\n",
    "    \n",
    "    model_type = hp.Choice(\"d_model_type\", [\"concat\", \"hidden_concat\", \"projection\"])\n",
    "    if model_type == \"concat\":\n",
    "        with hp.conditional_scope(\"d_model_type\", [\"concat\"]):\n",
    "            y = Embedding(10, hp.Int(\"d_embedding_dim\", 10, 100, step=10))(input_label)\n",
    "            y = DenselyConnected(32*32, sn=hp.Boolean(\"d_concat_sn\"))(y)\n",
    "            y = tf.keras.activations.relu(y, alpha=hp.Float(\"d_lrelu_concat\", 0.0, 0.3, step=0.1))\n",
    "            y = tf.reshape(y, [-1, 32, 32, 1])\n",
    "            xy = Concatenate()([input_image, y])\n",
    "    d_concat_stage = hp.Int(\"d_concat_stage\", 0, 2)   \n",
    "    for i in range(3):\n",
    "\n",
    "            xy = Convolution(128*(2**i), kernel_size=hp.Int(\"d_kernel_size_\" + str(i), 3, 5), \n",
    "                             sn=hp.Boolean(\"d_spectral_conv_\"+ str(i)), padding='same', strides=2)(xy)\n",
    "            xy = tf.keras.activations.relu(xy, alpha=hp.Float(\"d_lrelu_conv_\"+ str(i), 0.0, 0.3, step=0.1))\n",
    "            if model_type == \"hidden_concat\":\n",
    "                with hp.conditional_scope(\"d_model_type\", [\"hidden_concat\"]):\n",
    "                    if i == d_concat_stage:\n",
    "                        dim =32//(2**(i+1))\n",
    "                        y = Embedding(10, hp.Int(\"d_embedding_dim\", 10, 100, step=10))(input_label)\n",
    "                        y = DenselyConnected(dim*dim, sn=hp.Boolean(\"d_hidden_concat_sn_\"+str(i)))(y)\n",
    "                        y = tf.keras.activations.relu(y, alpha=hp.Float(\"d_lrelu_conv_\"+ str(i), 0.0, 0.3, step=0.1))\n",
    "                        y = tf.reshape(y, [-1, dim, dim, 1])\n",
    "                        xy = Concatenate()([xy, y])\n",
    "     \n",
    "    xy = tf.keras.activations.relu(xy, alpha=hp.Float(\"d_lrelu_pred\", 0.0, 0.3, step=0.1))\n",
    "    if model_type == \"projection\":\n",
    "            with hp.conditional_scope(\"d_model_type\", [\"projection\"]):    \n",
    "                outputs = Projection(xy, input_label, 10, sn=hp.Boolean(\"d_projection_sn\"))\n",
    "    if model_type == \"concat\" or model_type == \"hidden_concat\":\n",
    "            with hp.conditional_scope(\"d_model_type\", [\"concat\", \"hidden_concat\"]):  \n",
    "                xy = GlobalAveragePooling2D()(xy)\n",
    "                outputs = DenselyConnected(1, sn=hp.Boolean(model_type + \"_pred_sn\"))(xy)\n",
    "    model = tf.keras.Model(inputs=[input_image,input_label], outputs=outputs, name='Discriminator')\n",
    "    return model\n",
    "\n",
    "def build_generator(hp):\n",
    "        \n",
    "        input_z = tf.keras.Input(shape=(hp.Int(\"g_z_dim\",50, 300, step=10),))\n",
    "        input_label = tf.keras.Input(shape=(1,))\n",
    "        input_label_int = tf.cast(input_label, tf.int32)\n",
    "        \n",
    "        xy = DenselyConnected(4*4*hp.Int(\"g_z_dense\", 10, 512), sn=hp.Boolean(\"g_densely_z_sn\"))(input_z)\n",
    "        xy = tf.keras.activations.relu(xy, alpha=hp.Float(\"g_lrelu_densely_z\", 0.0, 0.3, step=0.1))\n",
    "        xy = tf.reshape(xy, [-1, 4, 4, hp.get(\"g_z_dense\")])\n",
    "        \n",
    "        \n",
    "        #xy = x\n",
    "        \n",
    "        model_type = hp.Choice(\"g_model_type\", [\"concat\", \"conditional\"])\n",
    "        \n",
    "        if model_type == \"concat\":\n",
    "            with hp.conditional_scope(\"g_model_type\", [\"concat\"]):\n",
    "                y = Embedding(10, hp.Int(\"g_concat_embedding_dim\", 10, 100, step=10))(input_label)\n",
    "                y = DenselyConnected(4*4, sn=hp.Boolean(\"g_concat_sn\"))(y)\n",
    "                y = tf.keras.activations.relu(y, alpha=hp.Float(\"g_lrelu_concat\", 0.0, 0.3, step=0.1))\n",
    "                y = tf.reshape(y, [-1, 4, 4, 1])\n",
    "                xy = Concatenate()([xy, y])\n",
    "            \n",
    "        if model_type == \"conditional\":\n",
    "            with hp.conditional_scope(\"g_model_type\", [\"conditional\"]):\n",
    "                cbn_type = hp.Choice(\"g_CBNType\", [\"label\", \"linear\"])\n",
    "                if cbn_type == \"linear\":\n",
    "                \n",
    "                    y = Embedding(10, hp.Int(\"g_linear_embedding_dim\", 10, 100, step=10))(input_label)\n",
    "                    y = tf.reshape(y, [-1, hp.get(\"g_linear_embedding_dim\")])\n",
    "                    y = Concatenate()([input_z, y])\n",
    "                \n",
    "        \n",
    "        for i in range(3):    \n",
    "            \n",
    "            xy = TransposedConvolution(512//pow(2,i), hp.Int(\"g_kernel_size_\" + str(i), 3, 5), sn=hp.Boolean(\"g_spectral_conv\" + str(i)), padding='same', kernel_initializer='glorot_normal', strides=2)(xy)\n",
    "            \n",
    "            if model_type == \"conditional\":\n",
    "                if cbn_type == \"label\":\n",
    "                    xy = ConditionalBatchNorm(num_classes=10)([xy, input_label_int])\n",
    "                else:\n",
    "                    xy = ConditionalDenseBatchNorm()([xy, y])\n",
    "            if model_type == \"concat\":\n",
    "                    xy = BatchNormalization()(xy)\n",
    "                    \n",
    "            xy = tf.keras.activations.relu(xy, alpha=hp.Float(\"g_lrelu_conv_\" + str(i), 0.0, 0.3, step=0.1))\n",
    "\n",
    "        outputs = Convolution(3, 3, sn=hp.Boolean(\"g_sn_output\"), activation='tanh', padding='same')(xy)\n",
    "        model = tf.keras.Model(inputs=[input_z, input_label], outputs=outputs, name='Generator')\n",
    "        return model\n",
    "\n",
    "    \n",
    "class GAN(tf.keras.Model):\n",
    "    def __init__(self, hp):\n",
    "        super(GAN, self).__init__()\n",
    "        self.g = build_generator(hp)\n",
    "        self.d = build_discriminator(hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project results/cifar10_custom_training/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from results/cifar10_custom_training/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "class MyTuner(kt.Tuner):\n",
    "    def run_trial(self, trial, train_ds):\n",
    "        hp = trial.hyperparameters\n",
    "\n",
    "        # Hyperparameters can be added anywhere inside `run_trial`.\n",
    "        # When the first trial is run, they will take on their default values.\n",
    "        # Afterwards, they will be tuned by the `Oracle`.\n",
    "        train_ds = train_ds.batch(hp.Int(\"batch_size\", 64, 256, step=64, default=64)).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "        model = self.hypermodel.build(trial.hyperparameters)\n",
    "        lr_d = hp.Float(\"learning_rate_d\", 0.0001, 0.0004, sampling=\"log\", default=0.0002)\n",
    "        lr_g = hp.Float(\"learning_rate_g\", 0.00005, 0.0002, sampling=\"log\", default=0.00005)\n",
    "        beta_1_d = hp.Float(\"beta1_d\", 0.0, 0.5)\n",
    "        beta_1_g = hp.Float(\"beta1_g\", 0.0, 0.5)\n",
    "        d_optimizer = tf.keras.optimizers.Adam(lr_d, beta_1=beta_1_d, beta_2=0.9)\n",
    "        g_optimizer = tf.keras.optimizers.Adam(lr_g, beta_1=beta_1_g, beta_2=0.9)\n",
    "        \n",
    "        def discriminator_loss(real_output, fake_output): \n",
    "        #return tf.reduce_mean(fake_output) - tf.reduce_mean(real_output)\n",
    "            return tf.reduce_mean(tf.nn.relu(1.0 - real_output)) + tf.reduce_mean(tf.nn.relu(1.0 + fake_output))\n",
    "\n",
    "        def generator_loss(fake_output):\n",
    "            return -tf.reduce_mean(fake_output)\n",
    "\n",
    "        @tf.function\n",
    "        def train_step_d(real_images, real_label):\n",
    "        \n",
    "            noise = tf.random.normal((hp.get(\"batch_size\"), hp.get(\"g_z_dim\")))\n",
    "            label = tf.random.uniform(shape=(hp.get(\"batch_size\"), 1), minval=0, maxval=10, dtype=tf.int64)\n",
    "            with tf.GradientTape() as disc_tape:\n",
    "\n",
    "                generated_images = model.g([noise, label],training=True)\n",
    "                fake_logits = model.d([generated_images, label], training=True)\n",
    "                real_logits = model.d([real_images, real_label], training=True)\n",
    "                disc_loss = discriminator_loss(real_logits, fake_logits)\n",
    "                #gp_loss = self.gradient_penalty(self.d, real_image, generated_image, real_label)\n",
    "                #disc_loss += gp_loss * self.lambda_gp\n",
    "            gradients_of_discriminator = disc_tape.gradient(disc_loss, model.d.trainable_variables)\n",
    "            d_optimizer.apply_gradients(zip(gradients_of_discriminator, model.d.trainable_variables))\n",
    "            gradient_norm = tf.linalg.global_norm(gradients_of_discriminator)\n",
    "            return disc_loss, fake_logits, real_logits, gradient_norm\n",
    "        \n",
    "        @tf.function  # Training function\n",
    "        def train_step_g():\n",
    "            noise = tf.random.normal((hp.get(\"batch_size\"), hp.get(\"g_z_dim\")))  # latent noise vector\n",
    "            label = tf.random.uniform(shape=(hp.get(\"batch_size\"), 1), minval=0, maxval=10, dtype=tf.int64)\n",
    "            with tf.GradientTape() as gen_tape:\n",
    "\n",
    "                generated_images = model.g([noise, label], training=True)\n",
    "                fake_logits = model.d([generated_images, label], training=True)\n",
    "                gen_loss = generator_loss(fake_logits)\n",
    "            gradients_of_generator = gen_tape.gradient(gen_loss, model.g.trainable_variables)\n",
    "            g_optimizer.apply_gradients(zip(gradients_of_generator, model.g.trainable_variables))\n",
    "            gradient_norm = tf.linalg.global_norm(gradients_of_generator)\n",
    "            return gen_loss, gradient_norm\n",
    "        \n",
    "        @tf.function\n",
    "        def generate(z,y):\n",
    "            return model.g([z,y], training=False)\n",
    "        # `self.on_epoch_end` reports results to the `Oracle` and saves the\n",
    "        # current state of the Model. The other hooks called here only log values\n",
    "        # for display but can also be overridden. For use cases where there is no\n",
    "        # natural concept of epoch, you do not have to call any of these hooks. In\n",
    "        # this case you should instead call `self.oracle.update_trial` and\n",
    "        # `self.oracle.save_model` manually.\n",
    "        s = tf.constant([0], dtype=tf.int64)\n",
    "        z = tf.random.normal((10, hp.get(\"g_z_dim\")))\n",
    "        y = tf.reshape(tf.range(0, 10, delta=1, dtype=tf.int64), [10, 1])\n",
    "        \n",
    "        y_list = [tf.fill([num_samples, 1], i) for i in range(10)]\n",
    "        \n",
    "        current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        model_path = \"Models/\" + current_time\n",
    "        Path(model_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        log_path = \"Logs/\" + current_time\n",
    "        Path(log_path).mkdir(parents=True, exist_ok=True)\n",
    "        writer = tf.summary.create_file_writer(log_path)\n",
    "            \n",
    "        template = 'Epoch: {}  Step: {}  G_loss: {}  D_loss {}'\n",
    "        for epoch in range(100):\n",
    "\n",
    "            for batch, label in train_ds:\n",
    "\n",
    "                d_loss, fake_logits, real_logits, d_norm = train_step_d(batch, label)\n",
    "                g_loss, g_norm = train_step_g()\n",
    "                \n",
    "                if s % 50 == 0:\n",
    "                    print(template.format(epoch, s, g_loss, d_loss))\n",
    "\n",
    "                \n",
    "                    #image = model.g([z,y], training=False) \n",
    "                    image = generate(z,y)\n",
    "                    #fake_images = [self.generate(z,y2) for y2 in y_list]\n",
    "                    #fid_classes, fid_scalar = fid.get_fid(fake_images)\n",
    "                    \n",
    "                    with writer.as_default():\n",
    "                        tf.summary.scalar(\"/1 Fake Output\", tf.reduce_mean(fake_logits), step=s)\n",
    "                        tf.summary.scalar(\"/1 Real Output\", tf.reduce_mean(real_logits), step=s)\n",
    "                        tf.summary.scalar(\"/2 G Loss\", g_loss, step=s)\n",
    "                        tf.summary.scalar(\"/2 D Loss\", d_loss, step=s)\n",
    "                        tf.summary.scalar(\"/3 D Gradient Norm\", d_norm, step=s)\n",
    "                        tf.summary.scalar(\"/3 G Gradient Norm\", g_norm, step=s)\n",
    "                        tf.summary.image(\"Generated Image\", cast_img(image), step=s, max_outputs=10)\n",
    "                            \n",
    "                s += 1\n",
    "            if epoch % 10 == 0 and epoch != 0:\n",
    "                \n",
    "                z_fid = tf.random.normal((10, num_samples, hp.get(\"g_z_dim\")))\n",
    "                fake_images = [generate(z_fi,y2) for y2, z_fi in zip(y_list, z_fid)]\n",
    "                fid_classes, fid_scalar = intraFID.get_fid(fake_images)\n",
    "                ssim_list = metrics.sample_ssim(model.g, 10, hp.get(\"g_z_dim\"), n_samples=100)\n",
    "                ssim_mean = np.mean(ssim_list)\n",
    "                with writer.as_default():\n",
    "                        #for count, ssim_class in enumerate(ssim_list):\n",
    "                            #tf.summary.scalar(\"/4 MS-SSIM for Class {}\".format(count), ssim_class, step=e)\n",
    "                        tf.summary.scalar(\"/4 MS-SSIM Mean\", ssim_mean, step=epoch)\n",
    "                        tf.summary.scalar(\"/5 Mean FID\", fid_scalar, step=epoch)\n",
    "                        #for count, fid_class in enumerate(fid_classes):\n",
    "                            #tf.summary.scalar(\"/5 Class FID {}\".format(count), fid_class, step=e)\n",
    "                            \n",
    "                self.oracle.update_trial(trial.trial_id, {'fid': fid_scalar})\n",
    "                self.save_model(trial.trial_id, model)\n",
    "                #self.g.save(model_path + \"/generator\")\n",
    "                #self.d.save(model_path + \"/discriminator\")\n",
    "                #self.on_epoch_end(trial, model, epoch, logs={\"loss\": epoch_loss})\n",
    "                #epoch_loss_metric.reset_states()\n",
    "\n",
    "\n",
    "tuner = MyTuner(\n",
    "    oracle=kt.oracles.BayesianOptimization(\n",
    "        objective=kt.Objective(\"fid\", \"min\"), max_trials=10\n",
    "    ),\n",
    "    hypermodel=GAN,\n",
    "    directory=\"results\",\n",
    "    project_name=\"cifar10_custom_training\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train, ds_info = tfds.load('cifar10', split='train+test', shuffle_files=True, as_supervised=True, with_info=True)\n",
    "\n",
    "def normalize_img(image, label):\n",
    "    \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "    #image = tf.image.resize(image, [w_dim, h_dim])\n",
    "    image = (tf.cast(image, tf.float32) / 128.) - 1.\n",
    "    return image, label\n",
    "\n",
    "ds_train = ds_train.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "\n",
    "\n",
    "tuner.search(train_ds=ds_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'g_z_dim': 260, 'g_z_dense': 184, 'g_densely_z_sn': False, 'g_lrelu_densely_z': 0.0, 'g_model_type': 'conditional', 'g_CBNType': 'linear', 'g_kernel_size_0': 4, 'g_spectral_conv0': True, 'g_lrelu_conv_0': 0.30000000000000004, 'g_kernel_size_1': 3, 'g_spectral_conv1': True, 'g_lrelu_conv_1': 0.2, 'g_kernel_size_2': 4, 'g_spectral_conv2': False, 'g_lrelu_conv_2': 0.2, 'g_sn_output': True, 'd_model_type': 'projection', 'd_kernel_size_0': 3, 'd_spectral_conv_0': False, 'd_lrelu_conv_0': 0.2, 'd_kernel_size_1': 4, 'd_spectral_conv_1': True, 'd_lrelu_conv_1': 0.30000000000000004, 'd_kernel_size_2': 3, 'd_spectral_conv_2': False, 'd_lrelu_conv_2': 0.1, 'd_lrelu_pred': 0.2, 'd_concat_stage': 1, 'batch_size': 128, 'learning_rate_d': 0.00022894833123711305, 'learning_rate_g': 0.00017284849450584436, 'beta1_d': 0.02713160345720983, 'beta1_g': 0.24735031833847654, 'g_linear_embedding_dim': 30, 'd_projection_sn': False}\n"
     ]
    }
   ],
   "source": [
    "best_hps = tuner.get_best_hyperparameters()[0]\n",
    "print(best_hps.values)\n",
    "\n",
    "best_model = tuner.get_best_models()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
